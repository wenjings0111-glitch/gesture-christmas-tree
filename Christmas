<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Interactive Luxury AI Christmas Tree</title>
    <style>
        body { margin: 0; overflow: hidden; background: #000; font-family: 'serif'; }
        #canvas-container { position: absolute; top: 0; left: 0; width: 100%; height: 100%; z-index: 1; }
        
        #ui-layer {
            position: absolute; top: 40px; width: 100%; text-align: center;
            z-index: 10; pointer-events: none;
        }

        h1 {
            color: #fceea7; font-size: 60px; margin: 0; cursor: pointer;
            pointer-events: auto; font-family: 'Georgia', serif;
            text-shadow: 0 0 20px rgba(252, 238, 167, 0.5);
            background: linear-gradient(to bottom, #fff, #eebb66);
            -webkit-background-clip: text; -webkit-text-fill-color: transparent;
        }

        #hand-warning {
            position: absolute; bottom: 20px; left: 50%; transform: translateX(-50%);
            color: #d4af37; border: 1px solid #d4af37; padding: 10px 20px;
            background: rgba(0,0,0,0.6); display: none; z-index: 20;
        }

        #webcam-preview {
            position: absolute; bottom: 10px; right: 10px;
            width: 160px; height: 120px; border: 1px solid #444; z-index: 20;
            transform: scaleX(-1); /* Mirror view */
        }
    </style>
    <script type="importmap">
        {
            "imports": {
                "three": "https://cdn.jsdelivr.net/npm/three@0.160.0/build/three.module.js",
                "three/addons/": "https://cdn.jsdelivr.net/npm/three@0.160.0/examples/jsm/",
                "@mediapipe/tasks-vision": "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/+esm"
            }
        }
    </script>
</head>
<body>

    <div id="ui-layer">
        <h1 onclick="document.getElementById('file-input').click()">Merry Christmas</h1>
        <p style="color: #d4af37; letter-spacing: 2px;">GESTURE CONTROL ACTIVE</p>
    </div>

    <div id="hand-warning">PLEASE SHOW YOUR HAND TO CAMERA</div>
    <input type="file" id="file-input" multiple accept="image/*" style="display: none;">
    <canvas id="webcam-preview"></canvas>
    <video id="webcam" autoplay playsinline style="display:none;"></video>
    <div id="canvas-container"></div>

    <script type="module">
        import * as THREE from 'three';
        import { EffectComposer } from 'three/addons/postprocessing/EffectComposer.js';
        import { RenderPass } from 'three/addons/postprocessing/RenderPass.js';
        import { UnrealBloomPass } from 'three/addons/postprocessing/UnrealBloomPass.js';
        import { FilesetResolver, HandLandmarker } from '@mediapipe/tasks-vision';

        // --- SCENE SETUP ---
        const scene = new THREE.Scene();
        const camera = new THREE.PerspectiveCamera(45, window.innerWidth / window.innerHeight, 0.1, 1000);
        camera.position.set(0, 2, 50);

        const renderer = new THREE.WebGLRenderer({ antialias: true });
        renderer.setSize(window.innerWidth, window.innerHeight);
        renderer.toneMapping = THREE.ReinhardToneMapping;
        document.getElementById('canvas-container').appendChild(renderer.domElement);

        const mainGroup = new THREE.Group();
        scene.add(mainGroup);

        // --- LIGHTING ---
        scene.add(new THREE.AmbientLight(0xffffff, 0.5));
        const pointLight = new THREE.PointLight(0xffd700, 2, 50);
        pointLight.position.set(0, 5, 5);
        scene.add(pointLight);

        // --- PARTICLES & PHOTOS ---
        let particles = [];
        const photoGroup = new THREE.Group();
        mainGroup.add(photoGroup);

        function createTreeParticles() {
            const geo = new THREE.BoxGeometry(0.4, 0.4, 0.4);
            const mat = new THREE.MeshStandardMaterial({ color: 0x063319 }); // Deep Green
            const goldMat = new THREE.MeshStandardMaterial({ color: 0xffd700, metalness: 1 });

            for(let i=0; i<1000; i++) {
                const mesh = new THREE.Mesh(geo, Math.random() > 0.8 ? goldMat : mat);
                const t = Math.random();
                const y = (t * 24) - 12;
                const r = 8 * (1 - t) + 0.5;
                const angle = t * 40 + Math.random() * Math.PI * 2;
                
                mesh.userData.treePos = new THREE.Vector3(Math.cos(angle)*r, y, Math.sin(angle)*r);
                mesh.userData.scatterPos = new THREE.Vector3((Math.random()-0.5)*40, (Math.random()-0.5)*40, (Math.random()-0.5)*40);
                
                mainGroup.add(mesh);
                particles.push(mesh);
            }
        }

        function addPhoto(url) {
            const loader = new THREE.TextureLoader();
            loader.load(url, (tex) => {
                const geometry = new THREE.PlaneGeometry(4, 4);
                const material = new THREE.MeshBasicMaterial({ map: tex, side: THREE.DoubleSide });
                const mesh = new THREE.Mesh(geometry, material);
                
                // Position logic
                mesh.userData.treePos = new THREE.Vector3((Math.random()-0.5)*10, (Math.random()-0.5)*15, (Math.random()-0.5)*5);
                mesh.userData.scatterPos = new THREE.Vector3((Math.random()-0.5)*30, (Math.random()-0.5)*30, (Math.random()-0.5)*10);
                mesh.userData.isPhoto = true;
                
                particles.push(mesh);
                photoGroup.add(mesh);
            });
        }

        // --- AI GESTURE LOGIC ---
        let handLandmarker;
        let currentMode = 'TREE'; // TREE, SCATTER, FOCUS
        const video = document.getElementById('webcam');

        async function initAI() {
            const vision = await FilesetResolver.forVisionTasks("https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/wasm");
            handLandmarker = await HandLandmarker.createFromOptions(vision, {
                baseOptions: { modelAssetPath: `https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task`, delegate: "GPU" },
                runningMode: "VIDEO", numHands: 1
            });
            startWebcam();
        }

        function startWebcam() {
            navigator.mediaDevices.getUserMedia({ video: true }).then((stream) => {
                video.srcObject = stream;
                video.addEventListener("loadeddata", predict);
            });
        }

        async function predict() {
            const result = handLandmarker.detectForVideo(video, performance.now());
            const warning = document.getElementById('hand-warning');
            
            if (result.landmarks && result.landmarks.length > 0) {
                warning.style.display = 'none';
                const hand = result.landmarks[0];
                // Simple gesture logic based on finger distance
                const dist = Math.hypot(hand[8].x - hand[4].x, hand[8].y - hand[4].y);
                if (dist < 0.05) currentMode = 'FOCUS';
                else if (hand[8].y < hand[6].y) currentMode = 'SCATTER';
                else currentMode = 'TREE';
            } else {
                warning.style.display = 'block';
                currentMode = 'TREE';
            }
            requestAnimationFrame(predict);
        }

        // --- ANIMATION LOOP ---
        const clock = new THREE.Clock();
        function animate() {
            requestAnimationFrame(animate);
            const dt = clock.getDelta();
            
            particles.forEach(p => {
                let target = currentMode === 'SCATTER' ? p.userData.scatterPos : p.userData.treePos;
                if (currentMode === 'FOCUS' && p.userData.isPhoto) {
                    target = new THREE.Vector3(0, 2, 40);
                    p.lookAt(camera.position);
                }
                p.position.lerp(target, 0.05);
            });

            if(currentMode === 'TREE') mainGroup.rotation.y += 0.01;
            renderer.render(scene, camera);
        }

        // Init
        createTreeParticles();
        // Default placeholder images
        addPhoto('https://picsum.photos/id/1067/400/400');
        addPhoto('https://picsum.photos/id/1080/400/400');
        initAI();
        animate();

        // Manual Upload
        document.getElementById('file-input').addEventListener('change', (e) => {
            const files = e.target.files;
            for(let f of files) {
                const url = URL.createObjectURL(f);
                addPhoto(url);
            }
        });
    </script>
</body>
</html>
